# Создание рекуррентной нейронной сети для прогнозирования финансов с использованием криптовалюты - Основы глубокого обучения с использованием Python, TensorFlow и Keras стр.8

По материалам https://pythonprogramming.net/cryptocurrency-recurrent-neural-network-deep-learning-python-tensorflow-keras/

Добро пожаловать в часть 8 серии "Глубокое обучение с помощью Python, Keras и Tensorflow". В этом уроке мы будем работать над использованием рекуррентной нейронной сети для прогнозирования на основе набора данных временных рядов, который будет представлять собой цены на криптовалюту.  

Всякий раз, когда я занимаюсь чем-либо, связанным с финансами, многие люди говорят, что они не понимают или не любят финансы. Если вы хотите, не стесняйтесь адаптировать это руководство к набору данных, который вам нравится. По сути, это просто последовательность функций, которые нас интересуют. Достаточно любого примера, в котором у вас есть последовательность функций.  

Данные, которые мы будем использовать, - это данные open, high, low, close, volume для биткойнов, Ethereum, Litecoin и Bitcoin Cash.  

Для наших целей здесь мы сосредоточимся только на столбцах Close and Volume. Что это такое? В Close столбце указана конечная цена в конце каждого интервала. В данном случае это интервалы в 1 минуту. Итак, в конце каждой минуты, какова была цена актива.  

Volume Столбец показывает, сколько активов было продано за каждый интервал, в данном случае за 1 минуту.  

В самых простых терминах Close это цена вещи. Volume насколько это важно.  

Хорошо, так что не слишком сложно.  

Теперь у нас есть несколько таких "вещей". Мы будем отслеживать Close Volume каждую минуту биткойны, лайткоины, Эфириум и биткойн Кэш.

Теория заключается в том, что все эти криптокоины связаны друг с другом. Можем ли мы предсказать будущие движения, скажем, `Litecoin`, проанализировав последние 60 минут цен и объемов для всех 4 из этих монет? Я бы предположил, что здесь `существует некоторая`, по крайней мере, `лучшая, чем случайная, взаимосвязь, которую может обнаружить рекуррентная нейронная сеть`.  

Только 1 способ узнать!  

Хорошо, так как же нам это сделать? Наши данные еще не представлены в каком-то красивом формате, где у нас есть последовательности, сопоставленные с целями. На самом деле, целей вообще нет. Это всего лишь несколько точек данных каждые 60 секунд. Итак, нам нужно кое-что сделать.  

Во-первых, нам нужно объединить цену и объем для каждой монеты в один набор функций, затем мы хотим взять эти наборы функций и объединить их в последовательности из 60 таких наборов функций. Это будет наш вклад.  

Хорошо, что насчет нашего вывода? Наши цели? Ну, мы пытаемся предсказать, будет ли цена расти или падать. Итак, нам нужно взять "цены" товара, который мы пытаемся предсказать. Давайте придерживаться утверждения, что мы пытаемся предсказать цену Litecoin. Итак, нам нужно получить будущую цену Litecoin, а затем определить, будет ли она выше или ниже текущей цены. Мы должны делать это на каждом этапе.  

Отлично, кроме того, нам нужно:  
- Сбалансируйте набор данных между покупками и продажами. Мы также можем использовать веса классов, но баланс лучше.
- Каким-то образом масштабируйте / нормализуйте данные.
- Создайте разумные примеры данных, которые работают с проблемой.
- ???
- Прибыль!  
Тогда давайте перейдем к делу. Нам нужны данные. Вот данные: обучающий набор данных по ценообразованию на криптовалюту. 
https://pythonprogramming.net/static/downloads/machine-learning-data/crypto_data.zip  
Загрузите это, затем извлеките его в каталоге вашего проекта. У вас должен быть каталог с именемcrypto_data, внутри которого должно быть четыре файла csv. Чтобы читать эти файлы и управлять ими, мы собираемся использовать библиотеку под названием pandas. Откройте консоль / терминал и выполнитеpip install pandas.  

Давайте просто посмотрим на один из этих файлов:


```python
import  pandas  as  pd

df = pd.read_csv("crypto_data/LTC-USD.csv", names=['time', 'low', 'high', 'open', 'close', 'volume'])

print(df.head())
```

             time        low       high       open      close      volume
    0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200
    1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024
    2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799
    3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067
    4  1528968900  96.279999  96.540001  96.500000  96.389999  524.539978
    

Это данные дляLTC-USD, которые являются просто значением в долларах США для Litecoin. Что мы хотим сделать, так это каким-то образом взять close и volume отсюда и объединить его с другими 3 криптовалютами.


```python
main_df = pd.DataFrame()  # Создание пустого DF

ratios = ["BTC-USD", "LTC-USD", "BCH-USD", "ETH-USD"]  # Список имен файлов, которые будем читать и загружать в DF
for ratio in ratios:  # Итерация по списку имен файлов
    print(ratio)
    dataset = f'crypto_data/{ratio}.csv'  # получить полный путь к файлу.
    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # чтение в определенном файле

    # переименовать volume и close, чтобы включить в название колонки тикер:
    df.rename(columns={"close": f"{ratio}_close", "volume": f"{ratio}_volume"}, inplace=True)

    df.set_index("time", inplace=True)  # время в индекс, для объединения таблиц с другими тикерами
    df = df[[f"{ratio}_close", f"{ratio}_volume"]]  # игнорировать другие столбцы, кроме цены и объема

    if len(main_df)==0: # если фрейм данных пуст
        main_df = df  # тогда это просто текущий df
    else:  # в противном случае присоедините эти данные к основным
        main_df = main_df.join(df)

main_df.fillna(method="ffill", inplace=True)  # если в данных есть пробелы, используйте ранее известные значения
main_df.dropna(inplace=True)
# print(main_df.head())  # how did we do??
print(main_df.to_string(max_rows=7, max_cols=10))
# print(main_df.to_markdown())
```

    BTC-USD
    LTC-USD
    BCH-USD
    ETH-USD
                BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume
    time                                                                                                                                  
    1528968720    6487.379883        7.706374      96.660004      314.387024     870.859985       26.856577     486.010010       26.019083
    1528968780    6479.410156        3.088252      96.570000       77.129799     870.099976        1.124300     486.000000        8.449400
    1528968840    6479.410156        1.404100      96.500000        7.216067     870.789978        1.749862     485.750000       26.994646
    ...                   ...             ...            ...             ...            ...             ...            ...             ...
    1535215080    6714.520020        1.021925      58.020000       23.802017     531.469971        0.013854     279.369995        1.311763
    1535215140    6715.000000        3.645508      58.020000        6.953497     531.479980        0.016900     279.660004       11.752819
    1535215200    6715.000000        0.513560      58.080002      202.403183     531.479980        0.299520     279.649994        8.351710
    

Далее нам нужно создать цель. Для этого нам нужно знать, какую цену мы пытаемся предсказать. Нам также нужно знать, как далеко мы хотим прогнозировать. Пока мы остановимся на Litecoin. Знание того, насколько далеко мы хотим предсказать, вероятно, также зависит от длины наших последовательностей. Если наша длина последовательности равна 3 (так ... 3 минуты), мы, вероятно, не сможем легко предсказать 10 минут. Если наша длина последовательности равна 300, 10 может быть не так сложно. Я бы хотел использовать последовательность длиной 60 и прогноз на будущее из 3. Мы могли бы также сделать прогноз регрессионным вопросом, используя линейную активацию с выходным слоем, но вместо этого я собираюсь просто использовать двоичную классификацию.  

Если цена вырастет за 3 минуты, то это покупка. Если он выйдет из строя через 3 минуты, не покупайте / продавайте. Имея все это в виду, я собираюсь ввести следующие константы:  


```python
SEQ_LEN = 60  # сколько времени предшествующей последовательности собирать для RNN
FUTURE_PERIOD_PREDICT = 3  # как далеко в будущее мы пытаемся предсказать?
RATIO_TO_PREDICT = "LTC-USD"
```

Далее я собираюсь создать простую классификационную функцию, которую мы вскоре будем использовать для сопоставления:  


```python
def classify(current, future):
    """ Классификация по таргету """
    if float(future) > float(current):  # Если будущая цена выше текущей
        return 1 
    else:
        return 0
```

Довольно просто. Эта функция будет принимать значения из 2 столбцов. Если столбец "будущее" выше, отлично, это 1 (покупка). В противном случае это 0 (продажа). Для этого, во-первых, нам нужна колонка future!


```python
main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)
```

A .shift просто сдвинет столбцы для нас, отрицательный сдвиг сдвинет их "вверх". Таким образом, сдвиг на 3 даст нам цену на 3 минуты в будущем, и мы просто назначаем это новому столбцу.  

Теперь, когда у нас есть будущие значения, мы можем использовать их для создания цели с помощью функции, которую мы создали выше.  


```python
main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))
```

Вышесказанное может сбить с толку. Начните с игнорирования list() части, это только в самом конце, которую я объясню через минуту.

Используется map() для отображения функции. Первый параметр здесь - это функция, которую мы хотим сопоставить (classify), затем следующие - это параметры этой функции. В этом случае текущая цена закрытия, а затем будущая цена.

map Часть - это то, что позволяет нам делать это по строкам для этих столбцов, но при этом делать это довольно быстро. Часть списка преобразует конечный результат в список, который мы можем просто задать в виде столбца.

Отлично, давайте проверим данные:


```python
print(main_df.to_string(max_rows=15, max_cols=15))
```

                BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume     future  target
    time                                                                                                                                                     
    1528968720    6487.379883        7.706374      96.660004      314.387024     870.859985       26.856577     486.010010       26.019083  96.389999       0
    1528968780    6479.410156        3.088252      96.570000       77.129799     870.099976        1.124300     486.000000        8.449400  96.519997       0
    1528968840    6479.410156        1.404100      96.500000        7.216067     870.789978        1.749862     485.750000       26.994646  96.440002       0
    1528968900    6479.979980        0.753000      96.389999      524.539978     870.000000        1.680500     486.000000       77.355759  96.470001       1
    1528968960    6480.000000        1.490900      96.519997       16.991997     869.989990        1.669014     486.000000        7.503300  96.400002       0
    1528969020    6477.220215        2.731950      96.440002       95.524078     869.450012        0.865200     485.989990       85.877251  96.400002       0
    1528969080    6480.000000        2.174240      96.470001      175.205307     869.989990       23.534929     485.989990      160.915192  96.400002       0
    ...                   ...             ...            ...             ...            ...             ...            ...             ...        ...     ...
    1535214840    6710.089844        1.293573      58.009998       93.464951     531.479980        0.044015     279.290009        4.150405  58.009998       0
    1535214900    6712.990234        2.330975      58.020000        0.823356     531.469971        1.761348     279.299988        5.566861  58.020000       0
    1535214960    6713.140137        0.769891      58.020000        6.434783     531.479980        1.208560     279.359985       11.280577  58.020000       0
    1535215020    6714.520020        1.002652      58.009998        7.301921     531.479980        0.016868     279.359985        8.790519  58.080002       1
    1535215080    6714.520020        1.021925      58.020000       23.802017     531.469971        0.013854     279.369995        1.311763        NaN       0
    1535215140    6715.000000        3.645508      58.020000        6.953497     531.479980        0.016900     279.660004       11.752819        NaN       0
    1535215200    6715.000000        0.513560      58.080002      202.403183     531.479980        0.299520     279.649994        8.351710        NaN       0
    

Выглядит великолепно! Давайте создавать последовательности и тренироваться!!!  

Не так быстро, Карл. Нам все еще нужно создать данные проверки, последовательности и нормализовать данные! У нас еще много работы. Мы рассмотрим это в следующем уроке, увидимся там!  
https://pythonprogramming.net/normalizing-sequences-deep-learning-python-tensorflow-keras/?completed=/cryptocurrency-recurrent-neural-network-deep-learning-python-tensorflow-keras/

В преддверии этого урока мы узнали о рекуррентных нейронных сетях, развернули одну из них на более простом наборе данных, и теперь мы работаем над тем, чтобы сделать это с более реалистичным набором данных, чтобы попытаться предсказать динамику цен на криптовалюту.

Первое, что я хотел бы сделать, это выделить нашу проверку/выборку данных. В прошлом все, что мы делали, это перетасовывали данные, а затем нарезали их. Имеет ли это смысл здесь?  

Проблема с этим методом заключается в том, что данные по своей сути являются последовательными, поэтому использование последовательностей, которые не появятся в будущем, вероятно, является ошибкой. Это связано с тем, что последовательности в нашем случае, например, с интервалом в 1 минуту, будут почти идентичными. Скорее всего, цель также будет той же (покупка или продажа). Из-за этого любое переоснащение, вероятно, фактически перейдет в набор проверки. Вместо этого мы хотим сократить нашу проверку, пока она еще в порядке. Я бы хотел взять последние 5% данных. Для этого мы сделаем:


```python
times = sorted(main_df.index.values)  # получаем времена
last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]   # получаем последние 5% времени

validation_main_df = main_df[(main_df.index >= last_5pct)]  # делаемданные проверки, в которых индекс находится в последних 5%
main_df = main_df[(main_df.index < last_5pct)]  # теперь main_df - это все данные до последних 5%
```

Далее нам нужно сбалансировать и нормализовать эти данные. В целом, мы хотим убедиться, что классы имеют одинаковое количество при обучении, поэтому наша модель не всегда предсказывает только один класс.  

Один из способов противодействовать этому - использовать веса классов, что позволяет увеличить потерю веса при менее частых классификациях. Тем не менее, я никогда лично не видел, чтобы это действительно было сопоставимо с реальным сбалансированным набором данных.  

Нам также нужно взять наши данные и составить из них последовательности.  

Итак ... нам нужно кое-что сделать! Мы начнем с создания функции, которая будет обрабатывать фреймы данных, поэтому мы можем просто сделать что-то вроде:  


```python
train_x, train_y = preprocess_df(main_df) 
validation_x, validation_y = preprocess_df(validation_main_df)
```

Давайте начнем с удаления столбца future (фактическая цель вызывается буквально target, и future столбец нужен только временно для его создания). Затем нам нужно масштабировать наши данные:


```python
from sklearn import preprocessing  # pip установите sklearn... если у вас его нет!

def preprocess_df(df):
    df = df.drop("future", 1)  # это больше не нужно.

    for col in df.columns:  # пройдите по всем столбцам
        if col != "target":  # нормализуйте все ... за исключением самой цели!
            df[col] = df[col].pct_change()  # изменение pct "нормализует" разные валюты (каждая криптомонета имеет значительно разные значения, нас действительно больше интересуют движения другой монеты)
            df.dropna(inplace=True)  # удалить nan, созданный с помощью pct_change
            df[col] = preprocessing.scale(df[col].values)  # масштаб от 0 до 1.

    df.dropna(inplace=True)  # снова очистка ... jic. Эти противные NAN любят подкрадываться.

    """ Хорошо, мы нормализовали и масштабировали данные! Далее нам нужно создать наши фактические последовательности. """
    sequential_data = []  # это список, который будет СОДЕРЖАТЬ последовательности
    prev_days = deque(maxlen=SEQ_LEN)  # Это будут наши фактические последовательности. Они сделаны с помощью deque, который сохраняет максимальную длину, выталкивая старые значения по мере поступления новых

    for i in df.values:  # перебирать значения
        prev_days.append([n for n in i[:-1]])  # сохранить все, кроме целевого
        if len(prev_days) == SEQ_LEN:  # убедитесь, что у нас есть 60 последовательностей!
            sequential_data.append([np.array(prev_days), i[-1]])  # добавьте этих плохих парней!

    random.shuffle(sequential_data)  # перемешайте для хорошей оценки.

    """
    Мы нормализовали и масштабировали наши данные. Далее мы хотим сбалансировать это.
    Продолжая работу с нашей preprocess_df функцией, мы можем сбалансировать, выполнив:
    """
    buys = []  # список, в котором будут храниться наши последовательности покупок и цели
    sells = []  # список, в котором будут храниться наши последовательности продаж и цели

    for seq, target in sequential_data:  # перебор последовательных данных
        if target == 0:  # если это "не покупка"
            sells.append([seq, target])  # добавить в список продаж
        elif target == 1:  # в противном случае, если целью является 1 ...
            buys.append([seq, target])  # это покупка!

    random.shuffle(buys)  # перетасуйте покупки
    random.shuffle(sells)  # перетасуйте продажи!

    lower = min(len(buys), len(sells))  # какая длина короче?

    buys = buys[:lower]  # убедитесь, что оба списка имеют только самую короткую длину.
    sells = sells[:lower]  # убедитесь, что оба списка имеют только самую короткую длину.

    sequential_data = buys+sells  # добавьте их вместе
    random.shuffle(sequential_data)  # еще один случай, чтобы модель не путалась со всеми 1 классом, а затем с другим.

    """ Теперь все, что нам нужно сделать, это разделить данные обратно на наборы функций и метки / цели. Достаточно просто: """
    X = []
    y = []

    for seq, target in sequential_data:  # going over our new sequential data
        X.append(seq)  # X is the sequences
        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)

    return np.array(X), y  # return X and y...and make X a numpy array! ..import numpy as np
```




```python

```
